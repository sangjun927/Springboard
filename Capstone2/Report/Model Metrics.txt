{\rtf1\ansi\ansicpg1252\cocoartf2580
\cocoatextscaling0\cocoaplatform0{\fonttbl\f0\fswiss\fcharset0 Arial-BoldMT;\f1\fswiss\fcharset0 ArialMT;}
{\colortbl;\red255\green255\blue255;\red0\green0\blue0;\red255\green255\blue255;}
{\*\expandedcolortbl;;\cssrgb\c0\c0\c0;\cssrgb\c100000\c100000\c100000;}
\margl1440\margr1440\vieww11520\viewh8400\viewkind0
\deftab720
\pard\pardeftab720\partightenfactor0

\f0\b\fs24 \cf2 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Model Evaluation:
\f1\b0 \
Random forest shows the best accuracy rate among four different models (Logistics Regression, Random Forest, Gradient Boosting, and Light GBM). Accuracy rate is 0.951 with 0.007 standard deviation. Model has been cross-validated with k-fold method, therefore the model is not overfitting. \
\
\

\f0\b Model Optimization:
\f1\b0 \
\pard\pardeftab720\partightenfactor0
\cf2 One of the disadvantages of random forest is that it could be slow when it comes to a large number of trees. I initially tried GridSearch optimization but it was too slow. Therefore, I used Bayesian Optimization. I tried to adjust three set of hyperparameters: max_feature, max_samples, and n_estimator. Below is the result of tuning.\
\
Best Target Value: \cb3 0.9520516366989396\'a0\cb1 \
\pard\pardeftab720\partightenfactor0
\cf2 \cb3 Hyperparameter #1 - max_feature: 0.5080833945225312\cb1 \
\cb3 Hyperparameter #2 - max_samples: 0.9788650855858045\cb1 \
\cb3 Hyperparameter #3 - n_estimator: 228.29994742665698}